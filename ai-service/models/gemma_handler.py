"""
LUCI (LUC1) - Ollama Gemma Model Handler
Handles inference for Gemma 1B model via Ollama API
"""

import requests
import json
from typing import Optional, Dict, List
from loguru import logger
import os
from pathlib import Path
import re
from european_logistics import EuropeanLogisticsService

class GemmaHandler:
    def __init__(self, model_name: str = "gemma3:1b", ollama_url: str = "http://localhost:11434"):
        """
        Initialize LUCI with Ollama Gemma model

        Args:
            model_name: Ollama model name
            ollama_url: Ollama server URL
        """
        self.model_name = model_name
        self.ollama_url = ollama_url
        self.is_loaded = False
        self.conversation_context = {}  # Para mantener contexto de conversaciones

        # Inicializar servicio de logÃ­stica europea
        self.logistics_service = EuropeanLogisticsService()

        logger.info(f"ðŸ¤– LUCI initialized with Ollama model: {model_name}")
        logger.info("ðŸšš European Logistics Service initialized for road transport")

    def load_model(self):
        """Check Ollama connection and model availability"""
        if self.is_loaded:
            logger.info("Model already loaded")
            return

        try:
            logger.info(f"Connecting to Ollama with model: {self.model_name}")

            # Test connection to Ollama
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [model["name"] for model in models]

                if self.model_name in model_names:
                    self.is_loaded = True
                    logger.success(f"âœ… LUCI connected to Ollama with {self.model_name}")
                else:
                    logger.warning(f"âš ï¸ Model {self.model_name} not found. Available: {model_names}")
                    self.is_loaded = False
            else:
                logger.error("âŒ Cannot connect to Ollama server")
                self.is_loaded = False

        except Exception as e:
            logger.error(f"âŒ Ollama connection error: {e}")
            self.is_loaded = False

    def extract_quote_data(self, text):
        """
        Extrae datos de cotizaciÃ³n del texto del usuario usando regex y anÃ¡lisis
        """
        data = {}

        # Detectar peso
        weight_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:kg|kilos?|kilogramos?)',
            r'(\d+(?:\.\d+)?)\s*(?:ton|toneladas?)',
            r'peso[:\s]*(\d+(?:\.\d+)?)',
        ]

        for pattern in weight_patterns:
            match = re.search(pattern, text.lower())
            if match:
                weight = float(match.group(1))
                if 'ton' in pattern:
                    weight *= 1000  # Convertir a kg
                data['weight_kg'] = weight
                break

        # Detectar dimensiones
        dimension_pattern = r'(\d+(?:\.\d+)?)\s*x\s*(\d+(?:\.\d+)?)\s*x\s*(\d+(?:\.\d+)?)\s*(?:cm|metros?|m)'
        match = re.search(dimension_pattern, text.lower())
        if match:
            l, w, h = map(float, match.groups())
            # Convertir a metros si estÃ¡ en cm
            if 'cm' in text.lower():
                l, w, h = l/100, w/100, h/100
            data['volume_m3'] = l * w * h

        # Detectar origen (siempre desde EspaÃ±a) y destino (ciudades europeas)
        spanish_cities = ['madrid', 'barcelona', 'valencia', 'sevilla', 'bilbao', 'zaragoza', 'mÃ¡laga']
        european_destinations = {
            'francia': ['parÃ­s', 'lyon', 'marsella', 'toulouse', 'niza', 'burdeos'],
            'alemania': ['berlÃ­n', 'mÃºnich', 'hamburgo', 'frankfurt', 'colonia', 'stuttgart'],
            'italia': ['roma', 'milÃ¡n', 'nÃ¡poles', 'turÃ­n', 'florencia', 'venecia'],
            'paÃ­ses bajos': ['Ã¡msterdam', 'rÃ³terdam', 'la haya', 'utrecht'],
            'bÃ©lgica': ['bruselas', 'amberes', 'gante', 'brujas'],
            'suiza': ['zurich', 'ginebra', 'berna', 'basilea'],
            'austria': ['viena', 'salzburgo', 'innsbruck', 'graz'],
            'portugal': ['lisboa', 'oporto', 'braga', 'coimbra'],
            'repÃºblica checa': ['praga', 'brno', 'ostrava'],
            'polonia': ['varsovia', 'cracovia', 'gdansk', 'wrocÅ‚aw']
        }

        # Origen por defecto siempre EspaÃ±a (Madrid si no se especifica)
        data['origin'] = 'Madrid'

        # Detectar ciudad de origen espaÃ±ola especÃ­fica
        for city in spanish_cities:
            if city in text.lower():
                if 'desde' in text.lower() or 'madrid' in text.lower():
                    data['origin'] = city.title()
                    break

        # Detectar destino europeo
        found_destination = False

        # Buscar ciudades especÃ­ficas primero
        for country, cities in european_destinations.items():
            for city in cities:
                if city in text.lower():
                    data['destination'] = city.title()
                    data['destination_country'] = country.title()
                    found_destination = True
                    break
            if found_destination:
                break

        # Si no se encontrÃ³ ciudad especÃ­fica, buscar por paÃ­s
        if not found_destination:
            for country in european_destinations.keys():
                if country in text.lower():
                    data['destination'] = country.title()
                    data['destination_country'] = country.title()
                    found_destination = True
                    break

        # Detectar tipo de carga
        cargo_types = {
            'electrÃ³nicos': 'electronica',
            'electrÃ³nica': 'electronica',
            'computadores': 'electronica',
            'mÃ³viles': 'electronica',
            'frÃ¡gil': 'carga_fragil',
            'delicado': 'carga_fragil',
            'quÃ­micos': 'quimicos',
            'quÃ­mico': 'quimicos',
            'alimentos': 'alimentarios',
            'comida': 'alimentarios'
        }

        for key, value in cargo_types.items():
            if key in text.lower():
                data['cargo_type'] = value
                break

        # Detectar tipo de transporte
        transport_types = {
            'aÃ©reo': 'aereo',
            'aviÃ³n': 'aereo',
            'aire': 'aereo',
            'marÃ­timo': 'maritimo',
            'barco': 'maritimo',
            'mar': 'maritimo',
            'terrestre': 'terrestre',
            'carretera': 'terrestre',
            'camiÃ³n': 'terrestre'
        }

        for key, value in transport_types.items():
            if key in text.lower():
                data['transport_type'] = value
                break

        # Detectar valor declarado
        value_pattern = r'valor[:\s]*(?:usd?)?\s*(\d+(?:,\d{3})*(?:\.\d{2})?)'
        match = re.search(value_pattern, text.lower())
        if match:
            value_str = match.group(1).replace(',', '')
            data['declared_value'] = float(value_str)

        return data

    def generate_quote(self, quote_data):
        """
        Genera una cotizaciÃ³n real para transporte terrestre europeo
        """
        try:
            logger.info("ðŸšš Generando cotizaciÃ³n de transporte terrestre europeo...")

            # Usar el servicio de logÃ­stica europea
            quote = self.logistics_service.generate_european_quote(quote_data)

            if not quote:
                logger.error("No se pudo generar cotizaciÃ³n europea")
                return None

            logger.info(f"âœ… CotizaciÃ³n generada: {quote['origen']} â†’ {quote['destino']}")
            return quote

        except Exception as e:
            logger.error(f"Error generating European quote: {e}")
            return None

    def format_quote_response(self, quote):
        """
        Formatea la cotizaciÃ³n europea en un texto profesional
        """
        if not quote:
            return "No pude generar la cotizaciÃ³n con los datos proporcionados. Por favor, proporciona mÃ¡s detalles sobre el destino europeo."

        response = f"""
ðŸšš **COTIZACIÃ“N TRANSPORTE TERRESTRE EUROPEO - LUC1**

**DETALLES DEL ENVÃO:**
ðŸ‡ªðŸ‡¸ Origen: {quote['origen']}, EspaÃ±a
ðŸŽ¯ Destino: {quote['destino']}
âš–ï¸ Peso: {quote['peso_kg']} kg
ðŸ“‹ Tipo de carga: {quote['tipo_carga'].replace('_', ' ').title()}
ðŸš› Transporte: {quote['tipo_transporte'].title()}
ðŸ“ Distancia: {quote['distancia_km']} km
ðŸ—ºï¸ PaÃ­ses de trÃ¡nsito: {', '.join(quote.get('paises_transito', []))}
ðŸ“… Fecha recogida: {quote['fecha_recogida']}

**COSTOS DETALLADOS (EUR):**
ðŸšš Transporte: â‚¬{quote['costo_transporte_eur']:.2f}
â›½ Combustible: â‚¬{quote['costo_combustible_eur']:.2f}
ðŸ›£ï¸ Peajes: â‚¬{quote['costo_peajes_eur']:.2f}
ðŸ›¡ï¸ Seguro: â‚¬{quote['costo_seguro_eur']:.2f}

ðŸ’¶ **TOTAL: â‚¬{quote['costo_total_eur']:.2f} EUR**

â° **TIEMPOS:**
ðŸ“¦ Entrega estimada: {quote['tiempo_estimado_dias']} dÃ­a(s)
ðŸš— Horas de conducciÃ³n: {quote['horas_conduccion']} h"""

        # Agregar informaciÃ³n sobre restricciones si existen
        if quote.get('alertas_criticas', 0) > 0:
            response += f"\n\nâš ï¸ **ALERTAS IMPORTANTES:** {quote['alertas_criticas']} restricciÃ³n(es) crÃ­tica(s)"

        if quote.get('restricciones'):
            response += "\nðŸš« **RESTRICCIONES DETECTADAS:**"
            for restriction in quote['restricciones'][:3]:  # Mostrar mÃ¡ximo 3
                if restriction.get('severity') == 'critical':
                    response += f"\n   ðŸš¨ {restriction.get('message', 'RestricciÃ³n crÃ­tica')}"
                elif restriction.get('severity') == 'warning':
                    response += f"\n   âš ï¸ {restriction.get('message', 'Advertencia')}"

        if quote.get('festivos_ruta'):
            response += f"\nðŸŽ‰ **FESTIVOS EN RUTA:** {len(quote['festivos_ruta'])} detectado(s)"

        response += f"\n\nðŸ“‹ **VEHÃCULO ASIGNADO:** {quote['vehiculo']['type'].title()} - {quote['vehiculo']['weight']}t"
        response += f"\nðŸ“… **VALIDEZ:** {quote['validez_dias']} dÃ­as"
        response += "\n\nÂ¿Necesitas informaciÃ³n sobre restricciones especÃ­ficas o ajustar la fecha?"

        return response.strip()

    def detect_quote_intent(self, text):
        """
        Detecta si el usuario estÃ¡ solicitando una cotizaciÃ³n
        """
        quote_keywords = [
            'cotizaciÃ³n', 'cotizacion', 'precio', 'costo', 'tarifa',
            'cuanto cuesta', 'cuÃ¡nto cuesta', 'precio de envÃ­o',
            'enviar', 'transportar', 'llevar', 'mandar'
        ]

        text_lower = text.lower()
        return any(keyword in text_lower for keyword in quote_keywords)

    def generate_response(
        self,
        prompt: str,
        max_length: int = 512,
        temperature: float = 0.7,
        top_p: float = 0.9,
        system_prompt: Optional[str] = None
    ) -> str:
        """
        Generate a response from LUCI - Demo mode with smart responses

        Args:
            prompt: User's input message
            max_length: Maximum tokens to generate
            temperature: Sampling temperature (0.0 to 1.0)
            top_p: Nucleus sampling parameter
            system_prompt: System instructions for LUCI

        Returns:
            Generated response text
        """
        if not self.is_loaded:
            self.load_model()

        if not self.is_loaded:
            return "âŒ LUCI no estÃ¡ disponible en este momento. Por favor, verifica que Ollama estÃ© ejecutÃ¡ndose."

        try:
            # Detectar si el usuario solicita una cotizaciÃ³n
            if self.detect_quote_intent(prompt):
                logger.info("CotizaciÃ³n detectada, procesando datos...")

                # Extraer datos de la solicitud
                quote_data = self.extract_quote_data(prompt)
                logger.info(f"Datos extraÃ­dos: {quote_data}")

                # Generar cotizaciÃ³n
                quote = self.generate_quote(quote_data)

                if quote:
                    return self.format_quote_response(quote)
                else:
                    # Si no se pudo generar cotizaciÃ³n automÃ¡tica, pedir mÃ¡s informaciÃ³n
                    missing_info = []
                    if not quote_data.get('weight_kg'):
                        missing_info.append("peso")
                    if not quote_data.get('destination'):
                        missing_info.append("destino")
                    if not quote_data.get('origin'):
                        missing_info.append("origen")

                    if missing_info:
                        return f"Para generar una cotizaciÃ³n precisa, necesito que me proporciones: {', '.join(missing_info)}. TambiÃ©n serÃ­a Ãºtil conocer el tipo de carga y dimensiones aproximadas."
                    else:
                        return "EncontrÃ© un problema generando la cotizaciÃ³n. Â¿PodrÃ­as verificar los datos proporcionados?"

            # Para preguntas generales sobre logÃ­stica, dar respuestas bÃ¡sicas sin usar Ollama
            general_keywords = ['hola', 'ayuda', 'servicios', 'que haces', 'quien eres']
            if any(keyword in prompt.lower() for keyword in general_keywords):
                return "Â¡Hola! Soy LUC1, tu asistente especializado en transporte terrestre europeo. Puedo generar cotizaciones desde EspaÃ±a hacia cualquier destino en Europa, incluyendo cÃ¡lculo de peajes, restricciones de trÃ¡fico y festivos. Â¿A quÃ© destino europeo necesitas enviar?"

            # Si no es solicitud de cotizaciÃ³n ni pregunta general, usar respuesta de IA
            default_system = """Eres LUC1, un agente especializado en transporte terrestre europeo desde EspaÃ±a. Tu funciÃ³n principal es:

1. GENERAR COTIZACIONES para transporte terrestre desde EspaÃ±a hacia destinos europeos
2. Calcular peajes europeos usando TollGuru y OpenRouteService
3. Detectar restricciones de trÃ¡fico en tiempo real (DGT EspaÃ±a, festivos europeos)
4. Asesorar sobre regulaciones de transporte por carretera en Europa
5. Optimizar rutas considerando restricciones de fin de semana y festivos

IMPORTANTE:
- Origen SIEMPRE desde EspaÃ±a (Madrid por defecto)
- Destinos SOLO europeos (Francia, Alemania, Italia, etc.)
- Transporte TERRESTRE exclusivamente (camiones/furgonetas)
- Incluir costos de peajes, combustible y restricciones
- Alertar sobre prohibiciones de circulaciÃ³n (domingos en Alemania/Austria)
- Considerar festivos nacionales que afecten el transporte

Responde siempre en espaÃ±ol, enfocado en logÃ­stica terrestre europea."""

            final_system_prompt = system_prompt if system_prompt else default_system

            # Prepare request for Ollama
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "system": final_system_prompt,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "top_p": top_p,
                    "num_predict": max_length
                }
            }

            # Send request to Ollama
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                return result.get("response", "No se pudo generar respuesta.")
            else:
                logger.error(f"Ollama API error: {response.status_code}")
                return "Error al comunicarse con el modelo de IA."

        except requests.exceptions.Timeout:
            logger.error("Timeout calling Ollama API")
            return "La respuesta estÃ¡ tardando demasiado. Por favor, intenta de nuevo."
        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return "Lo siento, tuve un problema al procesar tu mensaje. Â¿PodrÃ­as intentarlo de nuevo?"

    def generate_streaming_response(
        self,
        prompt: str,
        max_length: int = 512,
        temperature: float = 0.7,
        system_prompt: Optional[str] = None
    ):
        """
        Generate a streaming response from LUCI using Ollama (for real-time chat)
        Yields tokens as they are generated
        """
        if not self.is_loaded:
            self.load_model()

        if not self.is_loaded:
            yield "âŒ LUCI no estÃ¡ disponible en este momento."
            return

        try:
            # Default system prompt
            default_system = """Eres LUC1, un asistente inteligente especializado en logÃ­stica. Responde en espaÃ±ol, de forma profesional y Ãºtil."""
            final_system_prompt = system_prompt if system_prompt else default_system

            # Prepare request for Ollama streaming
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "system": final_system_prompt,
                "stream": True,
                "options": {
                    "temperature": temperature,
                    "num_predict": max_length
                }
            }

            # Send streaming request to Ollama
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=30,
                stream=True
            )

            if response.status_code == 200:
                for line in response.iter_lines():
                    if line:
                        try:
                            data = json.loads(line.decode('utf-8'))
                            if 'response' in data:
                                yield data['response']
                            if data.get('done', False):
                                break
                        except json.JSONDecodeError:
                            continue
            else:
                yield "Error al comunicarse con el modelo de IA."

        except Exception as e:
            logger.error(f"Error in streaming generation: {e}")
            yield "Error generando respuesta"

    def clear_cache(self):
        """Clear model connection"""
        self.is_loaded = False
        logger.info("Model connection cleared")

# Singleton instance
_luci_instance: Optional[GemmaHandler] = None

def get_luci_instance() -> GemmaHandler:
    """Get or create LUCI instance"""
    global _luci_instance
    if _luci_instance is None:
        _luci_instance = GemmaHandler()
    return _luci_instance